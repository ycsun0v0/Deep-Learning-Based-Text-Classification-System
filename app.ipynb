{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\61477\\AppData\\Local\\Temp\\ipykernel_11812\\2587507440.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(config.save_path, map_location=torch.device('cuda')))\n",
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Jan/2025 19:19:08] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Jan/2025 19:19:08] \"GET /static/pic/background.jpg HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [06/Jan/2025 19:19:08] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [06/Jan/2025 19:19:11] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Jan/2025 19:19:11] \"GET /static/pic/background.jpg HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template, jsonify\n",
    "import torch\n",
    "import os\n",
    "import pickle as pkl\n",
    "from importlib import import_module\n",
    "\n",
    "# 设置默认参数\n",
    "UNK, PAD = '<UNK>', '<PAD>'\n",
    "dataset_name = \"THUCNews\"  # 设置数据集名称\n",
    "key = {\n",
    "    0: '财经',\n",
    "    1: '房产',\n",
    "    2: '股票',\n",
    "    3: '教育',\n",
    "    4: '科技',\n",
    "    5: '社会',\n",
    "    6: '政治',\n",
    "    7: '体育',\n",
    "    8: '游戏',\n",
    "    9: '娱乐'\n",
    "}\n",
    "\n",
    "\n",
    "# 预定义两个模型名称\n",
    "MODEL_NAMES = [\"TextCNN\", \"TextRNN\"]  \n",
    "\n",
    "# 模型和配置字典\n",
    "models = {}\n",
    "configs = {}\n",
    "\n",
    "# 加载模型函数\n",
    "def init_model(model_name):\n",
    "    if model_name in models:\n",
    "        return models[model_name], configs[model_name]\n",
    "    \n",
    "    x = import_module('models.' + model_name)\n",
    "    config = x.Config(dataset_name, embedding='random')\n",
    "    \n",
    "    if os.path.exists(config.vocab_path):\n",
    "        vocab = pkl.load(open(config.vocab_path, 'rb'))\n",
    "        config.n_vocab = len(vocab)\n",
    "    \n",
    "    model = x.Model(config).to(config.device)\n",
    "    model.load_state_dict(torch.load(config.save_path, map_location=torch.device('cuda')))\n",
    "    model.eval()\n",
    "\n",
    "    # 缓存模型和配置\n",
    "    models[model_name] = model\n",
    "    configs[model_name] = config\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "# 初始化 Flask 应用\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 在启动时加载 TextCNN 和 TextRNN 模型\n",
    "for model_name in MODEL_NAMES:\n",
    "    init_model(model_name)\n",
    "\n",
    "def build_predict_text(text, use_word, config, vocab):\n",
    "    if use_word:\n",
    "        tokenizer = lambda x: x.split(' ')\n",
    "    else:\n",
    "        tokenizer = lambda x: [y for y in x]\n",
    "\n",
    "    token = tokenizer(text)\n",
    "    seq_len = len(token)\n",
    "    pad_size = config.pad_size\n",
    "    if pad_size:\n",
    "        if len(token) < pad_size:\n",
    "            token.extend([PAD] * (pad_size - len(token)))\n",
    "        else:\n",
    "            token = token[:pad_size]\n",
    "            seq_len = pad_size\n",
    "\n",
    "    words_line = []\n",
    "    for word in token:\n",
    "        words_line.append(vocab.get(word, vocab.get(UNK)))\n",
    "\n",
    "    ids = torch.LongTensor([words_line]).to(config.device)\n",
    "    seq_len = torch.LongTensor(seq_len).to(config.device)\n",
    "\n",
    "    return ids, seq_len\n",
    "\n",
    "def predict(text, model, config, vocab):\n",
    "    data = build_predict_text(text, use_word=False, config=config, vocab=vocab)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predicted_index = torch.argmax(probabilities)\n",
    "        predicted_label = key[int(predicted_index)]\n",
    "        predicted_probability = round(probabilities[0, predicted_index].item() * 100, 2)\n",
    "\n",
    "    all_probabilities = {key[i]: round(probabilities[0, i].item() * 100, 2) for i in range(len(key))}\n",
    "    return predicted_label, predicted_probability, all_probabilities\n",
    "\n",
    "\n",
    "# 首页路由，显示文本输入表单\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# 预测路由，处理表单提交的文本\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def make_prediction():\n",
    "    # 获取用户选择的模型\n",
    "    selected_model = request.form.get('model', 'TextCNN')\n",
    "    \n",
    "    # 获取相应的模型和配置\n",
    "    model, config = init_model(selected_model)\n",
    "\n",
    "    # 获取模型的词汇表\n",
    "    vocab = pkl.load(open(config.vocab_path, 'rb'))\n",
    "\n",
    "    text = request.form['text']\n",
    "    if text:\n",
    "        label, probability, all_probs = predict(text, model, config, vocab)\n",
    "        return render_template('index.html', label=label, probability=probability, all_probs=all_probs, input_text=text, selected_model=selected_model)\n",
    "    else:\n",
    "        return render_template('index.html', error=\"请输入文本进行预测。\", input_text=\"\", selected_model=selected_model)\n",
    "\n",
    "# 启动 Flask 应用\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\61477\\AppData\\Local\\Temp\\ipykernel_21372\\2134562271.py:6: The name tf.train.summary_iterator is deprecated. Please use tf.compat.v1.train.summary_iterator instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\python\\lib\\site-packages\\tensorflow\\python\\summary\\summary_iterator.py:27: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "loss/train: 2.3394477367401123\n",
      "loss/dev: 2.21150803565979\n",
      "acc/train: 0.125\n",
      "acc/dev: 0.24809999763965607\n",
      "loss/train: 1.023474931716919\n",
      "loss/dev: 0.6886829733848572\n",
      "acc/train: 0.6953125\n",
      "acc/dev: 0.7874000072479248\n",
      "loss/train: 0.9682983756065369\n",
      "loss/dev: 0.5889559388160706\n",
      "acc/train: 0.734375\n",
      "acc/dev: 0.8140000104904175\n",
      "loss/train: 0.6265930533409119\n",
      "loss/dev: 0.5263707041740417\n",
      "acc/train: 0.78125\n",
      "acc/dev: 0.8389999866485596\n",
      "loss/train: 1.0306557416915894\n",
      "loss/dev: 0.5194095373153687\n",
      "acc/train: 0.75\n",
      "acc/dev: 0.8422999978065491\n",
      "loss/train: 0.46502459049224854\n",
      "loss/dev: 0.4972032606601715\n",
      "acc/train: 0.84375\n",
      "acc/dev: 0.8468999862670898\n",
      "loss/train: 0.6193289160728455\n",
      "loss/dev: 0.47560593485832214\n",
      "acc/train: 0.8046875\n",
      "acc/dev: 0.8550000190734863\n",
      "loss/train: 0.693721354007721\n",
      "loss/dev: 0.4547249972820282\n",
      "acc/train: 0.7734375\n",
      "acc/dev: 0.8600999712944031\n",
      "loss/train: 0.5941688418388367\n",
      "loss/dev: 0.4451662003993988\n",
      "acc/train: 0.78125\n",
      "acc/dev: 0.8640999794006348\n",
      "loss/train: 0.4815424084663391\n",
      "loss/dev: 0.4363574981689453\n",
      "acc/train: 0.8515625\n",
      "acc/dev: 0.8658999800682068\n",
      "loss/train: 0.5140272974967957\n",
      "loss/dev: 0.43018314242362976\n",
      "acc/train: 0.8359375\n",
      "acc/dev: 0.8687999844551086\n",
      "loss/train: 0.5337185859680176\n",
      "loss/dev: 0.434609591960907\n",
      "acc/train: 0.8515625\n",
      "acc/dev: 0.8626999855041504\n",
      "loss/train: 0.45812591910362244\n",
      "loss/dev: 0.4232833981513977\n",
      "acc/train: 0.8359375\n",
      "acc/dev: 0.8680999875068665\n",
      "loss/train: 0.645396888256073\n",
      "loss/dev: 0.4131867587566376\n",
      "acc/train: 0.796875\n",
      "acc/dev: 0.8716999888420105\n",
      "loss/train: 0.7059065699577332\n",
      "loss/dev: 0.4064538776874542\n",
      "acc/train: 0.7890625\n",
      "acc/dev: 0.8751000165939331\n",
      "loss/train: 0.5772622227668762\n",
      "loss/dev: 0.4133892059326172\n",
      "acc/train: 0.8203125\n",
      "acc/dev: 0.8719000220298767\n",
      "loss/train: 0.3895385265350342\n",
      "loss/dev: 0.4079570770263672\n",
      "acc/train: 0.859375\n",
      "acc/dev: 0.8737000226974487\n",
      "loss/train: 0.45874160528182983\n",
      "loss/dev: 0.3932240605354309\n",
      "acc/train: 0.859375\n",
      "acc/dev: 0.879800021648407\n",
      "loss/train: 0.44690272212028503\n",
      "loss/dev: 0.40381523966789246\n",
      "acc/train: 0.90625\n",
      "acc/dev: 0.8769000172615051\n",
      "loss/train: 0.4185858368873596\n",
      "loss/dev: 0.38652968406677246\n",
      "acc/train: 0.8984375\n",
      "acc/dev: 0.8827000260353088\n",
      "loss/train: 0.36050891876220703\n",
      "loss/dev: 0.387633353471756\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8806999921798706\n",
      "loss/train: 0.5462613105773926\n",
      "loss/dev: 0.38338661193847656\n",
      "acc/train: 0.828125\n",
      "acc/dev: 0.881600022315979\n",
      "loss/train: 0.3654203414916992\n",
      "loss/dev: 0.3873681426048279\n",
      "acc/train: 0.8671875\n",
      "acc/dev: 0.8809000253677368\n",
      "loss/train: 0.3119391202926636\n",
      "loss/dev: 0.3803116977214813\n",
      "acc/train: 0.921875\n",
      "acc/dev: 0.8826000094413757\n",
      "loss/train: 0.44562679529190063\n",
      "loss/dev: 0.38960182666778564\n",
      "acc/train: 0.828125\n",
      "acc/dev: 0.8842999935150146\n",
      "loss/train: 0.2653364837169647\n",
      "loss/dev: 0.3751586973667145\n",
      "acc/train: 0.921875\n",
      "acc/dev: 0.8866000175476074\n",
      "loss/train: 0.4632219672203064\n",
      "loss/dev: 0.3794819414615631\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8837000131607056\n",
      "loss/train: 0.4112805128097534\n",
      "loss/dev: 0.376851886510849\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8823000192642212\n",
      "loss/train: 0.4680406451225281\n",
      "loss/dev: 0.37149161100387573\n",
      "acc/train: 0.8671875\n",
      "acc/dev: 0.8845999836921692\n",
      "loss/train: 0.41800835728645325\n",
      "loss/dev: 0.3704721927642822\n",
      "acc/train: 0.8828125\n",
      "acc/dev: 0.8873999714851379\n",
      "loss/train: 0.33912378549575806\n",
      "loss/dev: 0.37362420558929443\n",
      "acc/train: 0.8828125\n",
      "acc/dev: 0.8853999972343445\n",
      "loss/train: 0.36477091908454895\n",
      "loss/dev: 0.39293763041496277\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8801000118255615\n",
      "loss/train: 0.4560316205024719\n",
      "loss/dev: 0.3883899450302124\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8817999958992004\n",
      "loss/train: 0.43837007880210876\n",
      "loss/dev: 0.3751354515552521\n",
      "acc/train: 0.859375\n",
      "acc/dev: 0.8845000267028809\n",
      "loss/train: 0.47337591648101807\n",
      "loss/dev: 0.37511274218559265\n",
      "acc/train: 0.8671875\n",
      "acc/dev: 0.8877999782562256\n",
      "loss/train: 0.29975318908691406\n",
      "loss/dev: 0.3611513078212738\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8898000121116638\n",
      "loss/train: 0.19008983671665192\n",
      "loss/dev: 0.36885711550712585\n",
      "acc/train: 0.9453125\n",
      "acc/dev: 0.8888000249862671\n",
      "loss/train: 0.5883992910385132\n",
      "loss/dev: 0.37119776010513306\n",
      "acc/train: 0.796875\n",
      "acc/dev: 0.8871999979019165\n",
      "loss/train: 0.5105618238449097\n",
      "loss/dev: 0.372313916683197\n",
      "acc/train: 0.84375\n",
      "acc/dev: 0.8892999887466431\n",
      "loss/train: 0.4757341146469116\n",
      "loss/dev: 0.38933926820755005\n",
      "acc/train: 0.8515625\n",
      "acc/dev: 0.8784999847412109\n",
      "loss/train: 0.39611321687698364\n",
      "loss/dev: 0.3710784912109375\n",
      "acc/train: 0.90625\n",
      "acc/dev: 0.8870000243186951\n",
      "loss/train: 0.4558431804180145\n",
      "loss/dev: 0.36126619577407837\n",
      "acc/train: 0.828125\n",
      "acc/dev: 0.8903999924659729\n",
      "loss/train: 0.36591553688049316\n",
      "loss/dev: 0.3745043873786926\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8849999904632568\n",
      "loss/train: 0.36966001987457275\n",
      "loss/dev: 0.37402093410491943\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8853999972343445\n",
      "loss/train: 0.26075705885887146\n",
      "loss/dev: 0.3574962913990021\n",
      "acc/train: 0.90625\n",
      "acc/dev: 0.8935999870300293\n",
      "loss/train: 0.46045342087745667\n",
      "loss/dev: 0.3621002435684204\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8924000263214111\n",
      "loss/train: 0.31359240412712097\n",
      "loss/dev: 0.3679722845554352\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8901000022888184\n",
      "loss/train: 0.474552184343338\n",
      "loss/dev: 0.35377058386802673\n",
      "acc/train: 0.8984375\n",
      "acc/dev: 0.8925999999046326\n",
      "loss/train: 0.30115535855293274\n",
      "loss/dev: 0.362850546836853\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.8912000060081482\n",
      "loss/train: 0.2771383225917816\n",
      "loss/dev: 0.35770994424819946\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.89410001039505\n",
      "loss/train: 0.3080538511276245\n",
      "loss/dev: 0.3733241856098175\n",
      "acc/train: 0.921875\n",
      "acc/dev: 0.8931000232696533\n",
      "loss/train: 0.37529417872428894\n",
      "loss/dev: 0.3657139837741852\n",
      "acc/train: 0.8828125\n",
      "acc/dev: 0.8977000117301941\n",
      "loss/train: 0.38389354944229126\n",
      "loss/dev: 0.35228267312049866\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8996999859809875\n",
      "loss/train: 0.3579268455505371\n",
      "loss/dev: 0.36194074153900146\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8966000080108643\n",
      "loss/train: 0.48913270235061646\n",
      "loss/dev: 0.3658231496810913\n",
      "acc/train: 0.8984375\n",
      "acc/dev: 0.8942999839782715\n",
      "loss/train: 0.29061853885650635\n",
      "loss/dev: 0.37158530950546265\n",
      "acc/train: 0.921875\n",
      "acc/dev: 0.892300009727478\n",
      "loss/train: 0.1197725236415863\n",
      "loss/dev: 0.3550981283187866\n",
      "acc/train: 0.96875\n",
      "acc/dev: 0.8931000232696533\n",
      "loss/train: 0.30028030276298523\n",
      "loss/dev: 0.371785968542099\n",
      "acc/train: 0.921875\n",
      "acc/dev: 0.8906999826431274\n",
      "loss/train: 0.19350074231624603\n",
      "loss/dev: 0.3775457739830017\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.8919000029563904\n",
      "loss/train: 0.28871220350265503\n",
      "loss/dev: 0.3640343248844147\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8955000042915344\n",
      "loss/train: 0.251894474029541\n",
      "loss/dev: 0.37221071124076843\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.8909000158309937\n",
      "loss/train: 0.36830228567123413\n",
      "loss/dev: 0.37293878197669983\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8953999876976013\n",
      "loss/train: 0.2160845845937729\n",
      "loss/dev: 0.38954830169677734\n",
      "acc/train: 0.9609375\n",
      "acc/dev: 0.8902000188827515\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "log_file = r\"D:\\stu\\python_stu\\nlp\\文本分类组\\TextClassification\\THUCNews\\log\\TextCNN\\11-10_22.53\\events.out.tfevents.1731250402.zerone\"\n",
    "\n",
    "# 读取日志文件内容\n",
    "for event in tf.compat.v1.train.summary_iterator(log_file):\n",
    "    for value in event.summary.value:\n",
    "        print(f\"{value.tag}: {value.simple_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/train: 2.301801919937134\n",
      "loss/dev: 2.2840688228607178\n",
      "acc/train: 0.1171875\n",
      "acc/dev: 0.22609999775886536\n",
      "loss/train: 0.652897834777832\n",
      "loss/dev: 0.7139697670936584\n",
      "acc/train: 0.7734375\n",
      "acc/dev: 0.7696999907493591\n",
      "loss/train: 0.7688279747962952\n",
      "loss/dev: 0.5700805187225342\n",
      "acc/train: 0.7421875\n",
      "acc/dev: 0.819100022315979\n",
      "loss/train: 0.3927404582500458\n",
      "loss/dev: 0.5227805376052856\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8356000185012817\n",
      "loss/train: 0.6387857794761658\n",
      "loss/dev: 0.4629606008529663\n",
      "acc/train: 0.78125\n",
      "acc/dev: 0.8547000288963318\n",
      "loss/train: 0.35441115498542786\n",
      "loss/dev: 0.4396161437034607\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8640000224113464\n",
      "loss/train: 0.4423081874847412\n",
      "loss/dev: 0.43192365765571594\n",
      "acc/train: 0.8515625\n",
      "acc/dev: 0.8654999732971191\n",
      "loss/train: 0.32340118288993835\n",
      "loss/dev: 0.3998771607875824\n",
      "acc/train: 0.8828125\n",
      "acc/dev: 0.8716999888420105\n",
      "loss/train: 0.3911683261394501\n",
      "loss/dev: 0.3977448046207428\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8737000226974487\n",
      "loss/train: 0.3730642795562744\n",
      "loss/dev: 0.3723084032535553\n",
      "acc/train: 0.8984375\n",
      "acc/dev: 0.883400022983551\n",
      "loss/train: 0.2731196880340576\n",
      "loss/dev: 0.3746080994606018\n",
      "acc/train: 0.90625\n",
      "acc/dev: 0.881600022315979\n",
      "loss/train: 0.32306310534477234\n",
      "loss/dev: 0.3660470247268677\n",
      "acc/train: 0.9296875\n",
      "acc/dev: 0.8853999972343445\n",
      "loss/train: 0.3187519311904907\n",
      "loss/dev: 0.3455522358417511\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8891000151634216\n",
      "loss/train: 0.36568790674209595\n",
      "loss/dev: 0.35325339436531067\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8899999856948853\n",
      "loss/train: 0.3999783396720886\n",
      "loss/dev: 0.3463495373725891\n",
      "acc/train: 0.875\n",
      "acc/dev: 0.8907999992370605\n",
      "loss/train: 0.34549883008003235\n",
      "loss/dev: 0.32571089267730713\n",
      "acc/train: 0.890625\n",
      "acc/dev: 0.8989999890327454\n",
      "loss/train: 0.29946351051330566\n",
      "loss/dev: 0.34789589047431946\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.8903999924659729\n",
      "loss/train: 0.28848591446876526\n",
      "loss/dev: 0.33840832114219666\n",
      "acc/train: 0.90625\n",
      "acc/dev: 0.8950999975204468\n",
      "loss/train: 0.29467642307281494\n",
      "loss/dev: 0.32933855056762695\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.8934000134468079\n",
      "loss/train: 0.2656632363796234\n",
      "loss/dev: 0.3137047588825226\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.9004999995231628\n",
      "loss/train: 0.2173677384853363\n",
      "loss/dev: 0.3232709467411041\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.8955000042915344\n",
      "loss/train: 0.3182893395423889\n",
      "loss/dev: 0.3374113440513611\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.8921999931335449\n",
      "loss/train: 0.16703075170516968\n",
      "loss/dev: 0.32701486349105835\n",
      "acc/train: 0.953125\n",
      "acc/dev: 0.8973000049591064\n",
      "loss/train: 0.227726548910141\n",
      "loss/dev: 0.31589657068252563\n",
      "acc/train: 0.9453125\n",
      "acc/dev: 0.9003000259399414\n",
      "loss/train: 0.2149493545293808\n",
      "loss/dev: 0.33138588070869446\n",
      "acc/train: 0.921875\n",
      "acc/dev: 0.8992999792098999\n",
      "loss/train: 0.18539908528327942\n",
      "loss/dev: 0.3161987364292145\n",
      "acc/train: 0.9375\n",
      "acc/dev: 0.9035999774932861\n",
      "loss/train: 0.27578526735305786\n",
      "loss/dev: 0.341038316488266\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.892300009727478\n",
      "loss/train: 0.16604948043823242\n",
      "loss/dev: 0.30773231387138367\n",
      "acc/train: 0.9453125\n",
      "acc/dev: 0.9054999947547913\n",
      "loss/train: 0.23306767642498016\n",
      "loss/dev: 0.30876919627189636\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.9050999879837036\n",
      "loss/train: 0.28341466188430786\n",
      "loss/dev: 0.32050517201423645\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.9035999774932861\n",
      "loss/train: 0.16180077195167542\n",
      "loss/dev: 0.3186452388763428\n",
      "acc/train: 0.9453125\n",
      "acc/dev: 0.900600016117096\n",
      "loss/train: 0.13531386852264404\n",
      "loss/dev: 0.33737117052078247\n",
      "acc/train: 0.953125\n",
      "acc/dev: 0.8986999988555908\n",
      "loss/train: 0.21454890072345734\n",
      "loss/dev: 0.3316265344619751\n",
      "acc/train: 0.953125\n",
      "acc/dev: 0.9004999995231628\n",
      "loss/train: 0.1790827512741089\n",
      "loss/dev: 0.310530424118042\n",
      "acc/train: 0.9140625\n",
      "acc/dev: 0.9057000279426575\n",
      "loss/train: 0.15140604972839355\n",
      "loss/dev: 0.33148735761642456\n",
      "acc/train: 0.9375\n",
      "acc/dev: 0.9039999842643738\n",
      "loss/train: 0.09045582264661789\n",
      "loss/dev: 0.3410341441631317\n",
      "acc/train: 0.984375\n",
      "acc/dev: 0.9014999866485596\n",
      "loss/train: 0.1420939564704895\n",
      "loss/dev: 0.34173083305358887\n",
      "acc/train: 0.96875\n",
      "acc/dev: 0.9017000198364258\n",
      "loss/train: 0.1661922037601471\n",
      "loss/dev: 0.3222018778324127\n",
      "acc/train: 0.921875\n",
      "acc/dev: 0.9053000211715698\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "log_file = r\"D:\\stu\\python_stu\\nlp\\文本分类组\\TextClassification\\THUCNews\\log\\TextRNN\\11-12_10.52\\events.out.tfevents.1731379926.zerone\"\n",
    "\n",
    "# 读取日志文件内容\n",
    "for event in tf.compat.v1.train.summary_iterator(log_file):\n",
    "    for value in event.summary.value:\n",
    "        print(f\"{value.tag}: {value.simple_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
